from pyspark.sql import SparkSession 
from pyspark.sql.types import StructType, StructField 
from pyspark.sql.types import DoubleType, IntegerType, StringType,FloatType 
schema = StructType([StructField("S_Application_Category", StringType()),StructField("S_Division", StringType()),StructField("S_Division_type", StringType()),StructField("S_Calendar_month", StringType()),StructField("S_fiscalyear", StringType()),StructField("S_Region", StringType()),StructField("S_CompanyCode", StringType()),StructField("S_CompanyName", StringType()),StructField("S_Plant", StringType()),StructField("S_plantname", StringType()),StructField("S_Customer", StringType()),StructField("S_Customer_name", StringType()),StructField("S_Notification_No", StringType()),StructField("S_Damage_Text", StringType()),StructField("S_KPI", StringType()),StructField("S_Material", StringType()),StructField("S_Material_name", StringType()),StructField("N_Return_Order_Qty", FloatType()),StructField("N_Return_Order_Value", FloatType()),StructField("n_Price", FloatType()),StructField("N_Return_Delivery_Qty", FloatType()),StructField("N_Return_Delivery_Value", FloatType()),StructField("N_COPQ_QTY", FloatType()),StructField("N_COPQ_Value", FloatType()),StructField("N_Re_Dispatch_Qty", FloatType()),StructField("N_Re_Dispatch_Value", FloatType()),StructField("N_Available_Stock_Qty", FloatType()),StructField("N_Available_Stock_Value", FloatType()),StructField("N_ReWork_Input_excl_Scrap", FloatType()),StructField("N_Material_Transfer_Qty", FloatType()),StructField("N_Material_Transfer_Value", FloatType()),StructField("N_Remaining_Qty", FloatType()),StructField("N_Scrap_Write_Off_Qty", FloatType()),StructField("N_Scrap_Write_Off_Value", FloatType()),StructField("N_Block_Stock_Qty", FloatType()),StructField("N_Block_Stock_Value", FloatType()),StructField("N_Quality_Insp_Stock", FloatType()),StructField("N_Quality_Insp_Stock_Value", FloatType()),StructField("N_ReWork_Scrap", FloatType()),StructField("N_ReWork_Scrap_Value", FloatType()),StructField("N_No_Ret_Delv_Qty", FloatType()),StructField("N_No_Ret_Delv_Value", FloatType()),StructField("N_COPQ_1", FloatType()),StructField("N_COPQ_2", FloatType())]) 
spark = SparkSession.builder.appName("newcopq").config("spark.some.config.option", "sale").getOrCreate() 
df = spark.read.csv("D:/Shikha_working_directory/bi-vertib/datasource/csvFiles/newcopq1.csv",header=True,mode="DROPMALFORMED",sep=",",schema=schema) 
df.write.format("jdbc").options(url="jdbc:mysql://192.168.10.63:3306/epinsight",driver="com.mysql.cj.jdbc.Driver",dbtable="tbl_newcopq",user="root",password="Admin@123").mode("overwrite").save() 
